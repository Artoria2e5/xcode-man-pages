<!DOCTYPE html>
<html>
<!-- This is an automatically generated file.  Do not edit.
   -*- nroff -*-
 -->
<head>
  <meta charset="utf-8"/>
  <style>
    table.head, table.foot { width: 100%; }
    td.head-rtitle, td.foot-os { text-align: right; }
    td.head-vol { text-align: center; }
    div.Pp { margin: 1ex 0ex; }
    div.Nd, div.Bf, div.Op { display: inline; }
    span.Pa, span.Ad { font-style: italic; }
    span.Ms { font-weight: bold; }
    dl.Bl-diag > dt { font-weight: bold; }
    code.Nm, code.Fl, code.Cm, code.Ic, code.In, code.Fd, code.Fn,
    code.Cd { font-weight: bold; font-family: inherit; }
  </style>
  <title>MPSCNNGradientKernel(3)</title>
</head>
<body>
<table class="head">
  <tr>
    <td class="head-ltitle">MPSCNNGradientKernel(3)</td>
    <td class="head-vol">MetalPerformanceShaders.framework</td>
    <td class="head-rtitle">MPSCNNGradientKernel(3)</td>
  </tr>
</table>
<div class="manual-text">
<section class="Sh">
<h1 class="Sh" id="NAME"><a class="permalink" href="#NAME">NAME</a></h1>
MPSCNNGradientKernel
</section>
<section class="Sh">
<h1 class="Sh" id="SYNOPSIS"><a class="permalink" href="#SYNOPSIS">SYNOPSIS</a></h1>
<p class="Pp">#import &lt;MPSCNNKernel.h&gt;</p>
<p class="Pp">Inherits <b>MPSCNNBinaryKernel</b>.</p>
<p class="Pp">Inherited by <b>MPSCNNArithmeticGradient</b>,
    <b>MPSCNNBatchNormalizationGradient</b>,
    <b>MPSCNNBatchNormalizationStatisticsGradient</b>,
    <b>MPSCNNConvolutionGradient</b>,
    <b>MPSCNNCrossChannelNormalizationGradient</b>,
    <b>MPSCNNDropoutGradient</b>, <b>MPSCNNInstanceNormalizationGradient</b>,
    <b>MPSCNNLocalContrastNormalizationGradient</b>,
    <b>MPSCNNLogSoftMaxGradient</b>, <b>MPSCNNNeuronGradient</b>,
    <b>MPSCNNPoolingGradient</b>, <b>MPSCNNSoftMaxGradient</b>,
    <b>MPSCNNSpatialNormalizationGradient</b>, and
    <b>MPSCNNUpsamplingGradient</b>.</p>
<section class="Ss">
<h2 class="Ss" id="Instance_Methods"><a class="permalink" href="#Instance_Methods">Instance
  Methods</a></h2>
<br/>
(nonnull instancetype) - <b>initWithDevice:</b>
<br/>
(nullable instancetype) - <b>initWithCoder:device:</b>
<br/>
(<b>MPSImage</b> *__nonnull) -
  <b>encodeToCommandBuffer:sourceGradient:sourceImage:gradientState:</b>
<br/>
(void) -
  <b>encodeToCommandBuffer:sourceGradient:sourceImage:gradientState:destinationGradient:</b>
<br/>
(<b>MPSImageBatch</b> *__nonnull) -
  <b>encodeBatchToCommandBuffer:sourceGradients:sourceImages:gradientStates:</b>
<br/>
(void) -
  <b>encodeBatchToCommandBuffer:sourceGradients:sourceImages:gradientStates:destinationGradients:</b>
<br/>
<br/>
</section>
<section class="Ss">
<h2 class="Ss" id="Properties"><a class="permalink" href="#Properties">Properties</a></h2>
<br/>
NSInteger <b>kernelOffsetX</b>
<br/>
NSInteger <b>kernelOffsetY</b>
<br/>
<br/>
</section>
<section class="Ss">
<h2 class="Ss" id="Additional_Inherited_Members"><a class="permalink" href="#Additional_Inherited_Members">Additional
  Inherited Members</a></h2>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Detailed_Description"><a class="permalink" href="#Detailed_Description">Detailed
  Description</a></h1>
Gradient kernels are the backwards pass of a <b>MPSCNNKernel</b> used during
  training to calculate gradient back propagation. These take as arguments the
  gradient result from the next filter and the source image for the forward
  version of the filter. There is also a <b>MPSNNGradientState</b> passed from
  <b>MPSCNNKernel</b> to <b>MPSCNNGradientKernel</b> that contains information
  about the <b>MPSCNNKernel</b> parameters at the time it encoded and possibly
  also additional MTLResources to enable it to do its job.
<p class="Pp"></p>
<pre>
Training graph (partial):
    ---&gt; input image ---------&gt; MPSCNNKernel ------&gt;  resultImage ------&gt;--&gt;--&gt;--&gt;.
                   &#x00A0;                 |                                           |
                    '------.    MPSNNGradientState                         loss estimation
                            &#x00A0;        |                                           |
                             V        V                                           V
    &lt;--- result gradient &lt;- MPSCNNGradientKernel &lt;---  input gradient &lt;--&lt;--&lt;--&lt;---'
    In general operation, starting with the input image, the sequence of events is:
    1a)  Invoke padding policy to find result size for MPSCNNKernel.  This
         also configures some MPSCNNKernel parameters such as offset.
    1b)  Use the MPSImageDescriptor from 1a to make resultImage.
    1c)  Call MPSCNNKernel -encode...
    2) stages 1a-c are repeated for other forward passes in the inference portion of the graph
    3) We estimate the loss resulting from the whole inference computation so far (see MPSCNNLoss.h&gt;
    4) stages 5a-c are repeated for corresponding backward gradient passes in the graph
    5a) Invoke padding policy on the MPSCNNGradientKernel shown above. This sets the
        MPSCNNGradientKernel parameters to correspond with those in the forward pass
    5b) The result gradient for the MPSCNNGradientKernel is created from the MPSImageDescriptor from 5a
    5c) Call MPSCNNGradientKernel -encode with the input image, input gradient, result gradient and MPSNNGradientState
    6) pass the result gradient on to leftward gradient passes.
</pre>
<p class="Pp"></p>
<pre>
          For MPSCNNKernels that are trained, there may be other accompanying training kernels that
          need to be called in addition to the gradient kernel to update convolution weights or batch
          normalization parameters, for example. Steps 1a-c and 5a-c can be combined in a single -encode
          call. These return the result image or gradient out the left hand side.
          For purposes of inheritance the gradient image is the MPSCNNBinaryKernel primary image
          and the source image is the MPSCNNBinaryKernel secondary image. Various secondary properties
          such as kernel size are copies of the forward inference pass parameters of similar name
          are set automatically when -[MPSCNNGradientKernel destinationImageDescriptorForSourceImages:sourceStates:]
          is called.
</pre>
</section>
<section class="Sh">
<h1 class="Sh" id="Method_Documentation"><a class="permalink" href="#Method_Documentation">Method
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss" id="_-_(_fBMPSImageBatch_fP*__nonnull)_encodeBatchToCommandBuffer:_(__nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImageBatch_fP_*__nonnull)_sourceGradients(_fBMPSImageBatch_fP_*__nonnull)_sourceImages(_fBMPSStateBatch_fP_*__nonnull)_gradientStates"><a class="permalink" href="#_-_(_fBMPSImageBatch_fP*__nonnull)_encodeBatchToCommandBuffer:_(__nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImageBatch_fP_*__nonnull)_sourceGradients(_fBMPSImageBatch_fP_*__nonnull)_sourceImages(_fBMPSStateBatch_fP_*__nonnull)_gradientStates">-
  (<b>MPSImageBatch</b>*__nonnull) encodeBatchToCommandBuffer: (__nonnull id&lt;
  MTLCommandBuffer &gt;) commandBuffer(<b>MPSImageBatch</b> *__nonnull)
  sourceGradients(<b>MPSImageBatch</b> *__nonnull)
  sourceImages(<b>MPSStateBatch</b> *__nonnull) gradientStates</a></h2>
Encode a gradient filter and return a gradient During training, gradient filters
  are used to calculate the gradient associated with the loss for each feature
  channel in the forward pass source image. For those nodes that are trainable,
  these are then used to refine the value used in the trainable parameter. They
  consume a source gradient image which contains the gradients corresponding
  with the forward pass destination image, and calculate the gradients
  corresponding to the forward pass source image.
<p class="Pp"><b>A</b> gradient filter consumes a <b>MPSNNGradientState</b>
    object which captured various forward pass properties such as offset and
    edgeMode at the time the forward pass was encoded. These are transferred to
    the <b>MPSCNNBinaryKernel</b> secondary image properties automatically when
    this method creates its destination image.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> The MTLCommandBuffer on which to
  encode
<br/>
<i>sourceGradients</i> The gradient images from the 'next' filter in the graph
<br/>
<i>sourceImages</i> The images used as source image from the forward pass
<br/>
<i>gradientStates</i> The <b>MPSNNGradientState</b> or
  <b>MPSNNBinaryGradientState</b> subclass produced by the forward pass</div>
<p class="Pp">Reimplemented in
    <b>MPSCNNBatchNormalizationStatisticsGradient</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(void)_encodeBatchToCommandBuffer:_(__nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImageBatch_fP_*__nonnull)_sourceGradients(_fBMPSImageBatch_fP_*__nonnull)_sourceImages(_fBMPSStateBatch_fP_*__nonnull)_gradientStates(_fBMPSImageBatch_fP_*__nonnull)_destinationGradients"><a class="permalink" href="#_-_(void)_encodeBatchToCommandBuffer:_(__nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImageBatch_fP_*__nonnull)_sourceGradients(_fBMPSImageBatch_fP_*__nonnull)_sourceImages(_fBMPSStateBatch_fP_*__nonnull)_gradientStates(_fBMPSImageBatch_fP_*__nonnull)_destinationGradients">-
  (void) encodeBatchToCommandBuffer: (__nonnull id&lt; MTLCommandBuffer &gt;)
  commandBuffer(<b>MPSImageBatch</b> *__nonnull)
  sourceGradients(<b>MPSImageBatch</b> *__nonnull)
  sourceImages(<b>MPSStateBatch</b> *__nonnull)
  gradientStates(<b>MPSImageBatch</b> *__nonnull) destinationGradients</a></h2>
Encode a gradient filter and return a gradient During training, gradient filters
  are used to calculate the gradient associated with the loss for each feature
  channel in the forward pass source image. For those nodes that are trainable,
  these are then used to refine the value used in the trainable parameter. They
  consume a source gradient image which contains the gradients corresponding
  with the forward pass destination image, and calculate the gradients
  corresponding to the forward pass source image.
<p class="Pp"><b>A</b> gradient filter consumes a <b>MPSNNGradientState</b>
    object which captured various forward pass properties such as offset and
    edgeMode at the time the forward pass was encoded. These are transferred to
    the <b>MPSCNNBinaryKernel</b> secondary image properties automatically when
    you use -[<b>MPSCNNGradientKernel</b>
    destinationImageDescriptorForSourceImages:sourceStates:]. If you do not call
    this method, then you are responsible for configuring all of the primary and
    secondary image properties in <b>MPSCNNBinaryKernel</b>. Please see class
    description for expected ordering of operations.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> The MTLCommandBuffer on which to
  encode
<br/>
<i>sourceGradients</i> The gradient images from the 'next' filter in the graph
<br/>
<i>sourceImages</i> The image used as source images from the forward pass
<br/>
<i>gradientStates</i> An array of the <b>MPSNNGradientState</b> or
  <b>MPSNNBinaryGradientState</b> subclass produced by the forward pass
<br/>
<i>destinationGradients</i> The MPSImages into which to write the filter
  result</div>
<p class="Pp">Reimplemented in
    <b>MPSCNNBatchNormalizationStatisticsGradient</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(_fBMPSImage_fP*__nonnull)_encodeToCommandBuffer:_(__nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImage_fP_*__nonnull)_sourceGradient(_fBMPSImage_fP_*__nonnull)_sourceImage(_fBMPSState_fP_*__nonnull)_gradientState"><a class="permalink" href="#_-_(_fBMPSImage_fP*__nonnull)_encodeToCommandBuffer:_(__nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImage_fP_*__nonnull)_sourceGradient(_fBMPSImage_fP_*__nonnull)_sourceImage(_fBMPSState_fP_*__nonnull)_gradientState">-
  (<b>MPSImage</b>*__nonnull) encodeToCommandBuffer: (__nonnull id&lt;
  MTLCommandBuffer &gt;) commandBuffer(<b>MPSImage</b> *__nonnull)
  sourceGradient(<b>MPSImage</b> *__nonnull) sourceImage(<b>MPSState</b>
  *__nonnull) gradientState</a></h2>
Encode a gradient filter and return a gradient During training, gradient filters
  are used to calculate the gradient associated with the loss for each feature
  channel in the forward pass source image. For those nodes that are trainable,
  these are then used to refine the value used in the trainable parameter. They
  consume a source gradient image which contains the gradients corresponding
  with the forward pass destination image, and calculate the gradients
  corresponding to the forward pass source image.
<p class="Pp"><b>A</b> gradient filter consumes a <b>MPSNNGradientState</b>
    object which captured various forward pass properties such as offset and
    edgeMode at the time the forward pass was encoded. These are transferred to
    the <b>MPSCNNBinaryKernel</b> secondary image properties automatically when
    this method creates its destination image.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> The MTLCommandBuffer on which to
  encode
<br/>
<i>sourceGradient</i> The gradient image from the 'next' filter in the graph (in
  the inference direction)
<br/>
<i>sourceImage</i> The image used as source image by the forward inference pass
<br/>
<i>gradientState</i> The <b>MPSNNGradientState</b> or
  <b>MPSNNBinaryGradientState</b> subclass produced by the forward inference
  pass</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent">The result gradient from the gradient filter</div>
<p class="Pp">Reimplemented in
    <b>MPSCNNBatchNormalizationStatisticsGradient</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(void)_encodeToCommandBuffer:_(__nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImage_fP_*__nonnull)_sourceGradient(_fBMPSImage_fP_*__nonnull)_sourceImage(_fBMPSState_fP_*__nonnull)_gradientState(_fBMPSImage_fP_*__nonnull)_destinationGradient"><a class="permalink" href="#_-_(void)_encodeToCommandBuffer:_(__nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImage_fP_*__nonnull)_sourceGradient(_fBMPSImage_fP_*__nonnull)_sourceImage(_fBMPSState_fP_*__nonnull)_gradientState(_fBMPSImage_fP_*__nonnull)_destinationGradient">-
  (void) encodeToCommandBuffer: (__nonnull id&lt; MTLCommandBuffer &gt;)
  commandBuffer(<b>MPSImage</b> *__nonnull) sourceGradient(<b>MPSImage</b>
  *__nonnull) sourceImage(<b>MPSState</b> *__nonnull)
  gradientState(<b>MPSImage</b> *__nonnull) destinationGradient</a></h2>
Encode a gradient filter and return a gradient During training, gradient filters
  are used to calculate the gradient associated with the loss for each feature
  channel in the forward pass source image. For those nodes that are trainable,
  these are then used to refine the value used in the trainable parameter. They
  consume a source gradient image which contains the gradients corresponding
  with the forward pass destination image, and calculate the gradients
  corresponding to the forward pass source image.
<p class="Pp"><b>A</b> gradient filter consumes a <b>MPSNNGradientState</b>
    object which captured various forward pass properties such as offset and
    edgeMode at the time the forward pass was encoded. These are transferred to
    the <b>MPSCNNBinaryKernel</b> secondary image properties automatically when
    you use -[<b>MPSCNNGradientKernel</b>
    destinationImageDescriptorForSourceImages:sourceStates:]. If you do not call
    this method, then you are responsible for configuring all of the primary and
    secondary image properties in <b>MPSCNNBinaryKernel</b>. Please see class
    description for expected ordering of operations.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> The MTLCommandBuffer on which to
  encode
<br/>
<i>sourceGradient</i> The gradient image from the 'next' filter in the graph
<br/>
<i>sourceImage</i> The image used as source image from the forward pass
<br/>
<i>gradientState</i> The <b>MPSNNGradientState</b> and
  <b>MPSNNBinaryGradientState</b> subclass produced by the forward pass
<br/>
<i>destinationGradient</i> The <b>MPSImage</b> into which to write the filter
  result</div>
<p class="Pp">Reimplemented in
    <b>MPSCNNBatchNormalizationStatisticsGradient</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(nullable_instancetype)__fBinitWithCoder:_fP_(NSCoder_*__nonnull)_aDecoder(nonnull_id__MTLDevice__)_device"><a class="permalink" href="#_-_(nullable_instancetype)__fBinitWithCoder:_fP_(NSCoder_*__nonnull)_aDecoder(nonnull_id__MTLDevice__)_device">-
  (nullable instancetype) <b>initWithCoder:</b> (NSCoder *__nonnull)
  aDecoder(nonnull id&lt; MTLDevice &gt;) device</a></h2>
<b>NSSecureCoding</b> compatability While the standard NSSecureCoding/NSCoding
  method -initWithCoder: should work, since the file can't know which device
  your data is allocated on, we have to guess and may guess incorrectly. To
  avoid that problem, use initWithCoder:device instead.
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>aDecoder</i> The NSCoder subclass with your serialized
  <b>MPSKernel</b>
<br/>
<i>device</i> The MTLDevice on which to make the <b>MPSKernel</b></div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> new <b>MPSKernel</b> object, or nil if
  failure.</div>
<p class="Pp">Reimplemented from <b>MPSCNNBinaryKernel</b>.</p>
<p class="Pp">Reimplemented in <b>MPSCNNConvolutionGradient</b>,
    <b>MPSCNNFullyConnectedGradient</b>, <b>MPSCNNPoolingAverageGradient</b>,
    <b>MPSCNNPoolingMaxGradient</b>, <b>MPSCNNPoolingL2NormGradient</b>,
    <b>MPSCNNDilatedPoolingMaxGradient</b>, <b>MPSCNNSoftMaxGradient</b>,
    <b>MPSCNNLogSoftMaxGradient</b>,
    <b>MPSCNNCrossChannelNormalizationGradient</b>,
    <b>MPSCNNPoolingGradient</b>,
    <b>MPSCNNLocalContrastNormalizationGradient</b>,
    <b>MPSCNNBatchNormalizationGradient</b>,
    <b>MPSCNNBatchNormalizationStatisticsGradient</b>,
    <b>MPSCNNNeuronGradient</b>, <b>MPSCNNDropoutGradient</b>, and
    <b>MPSCNNSpatialNormalizationGradient</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(nonnull_instancetype)_initWithDevice:_(nonnull_id__MTLDevice__)_device"><a class="permalink" href="#_-_(nonnull_instancetype)_initWithDevice:_(nonnull_id__MTLDevice__)_device">-
  (nonnull instancetype) initWithDevice: (nonnull id&lt; MTLDevice &gt;)
  device</a></h2>
Standard init with default properties per filter type
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>device</i> The device that the filter will be used on.
  May not be NULL.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> pointer to the newly initialized object. This
  will fail, returning nil if the device is not supported. Devices must be
  MTLFeatureSet_iOS_GPUFamily2_v1 or later.</div>
<p class="Pp">Reimplemented from <b>MPSCNNBinaryKernel</b>.</p>
<p class="Pp">Reimplemented in <b>MPSCNNConvolutionGradient</b>,
    <b>MPSCNNFullyConnectedGradient</b>, <b>MPSCNNSoftMaxGradient</b>,
    <b>MPSCNNLogSoftMaxGradient</b>, <b>MPSCNNPoolingGradient</b>,
    <b>MPSCNNArithmeticGradient</b>, <b>MPSCNNNeuronGradient</b>,
    <b>MPSCNNUpsamplingGradient</b>, and <b>MPSCNNDropoutGradient</b>.</p>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Property_Documentation"><a class="permalink" href="#Property_Documentation">Property
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss" id="_-_kernelOffsetX_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_kernelOffsetX_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  kernelOffsetX [read]<b>, [write]</b>, [nonatomic]<b>, [assign]</b></a></h2>
Offset in the kernel reference frame to position the kernel in the X dimension
  In some cases, the input gradient must be upsampled with zero insertion to
  account for things like strides in the forward <b>MPSCNNKernel</b> pass. As
  such, the offset, which describes a X,Y offset in the source coordinate space
  is insufficient to fully describe the offset applied to a kernel. The kernel
  offset is the offset after upsampling. Both the source offset and kernel
  offset are additive: effective offset = source offset * stride + kernel
  offset. The offset is applied to the (upsampled) source gradient
</section>
<section class="Ss">
<h2 class="Ss" id="_-_kernelOffsetY_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_kernelOffsetY_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  kernelOffsetY [read]<b>, [write]</b>, [nonatomic]<b>, [assign]</b></a></h2>
Offset in the kernel reference frame to position the kernel in the Y dimension
  In some cases, the input gradient must be upsampled with zero insertion to
  account for things like strides in the forward <b>MPSCNNKernel</b> pass. As
  such, the offset, which describes a X,Y offset in the source coordinate space
  is insufficient to fully describe the offset applied to a kernel. The kernel
  offset is the offset after upsampling. Both the source offset and kernel
  offset are additive: effective offset = source offset * stride + kernel
  offset. The offset is applied to the (upsampled) source gradient
<p class="Pp"></p>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Author"><a class="permalink" href="#Author">Author</a></h1>
Generated automatically by Doxygen for MetalPerformanceShaders.framework from
  the source code.
</section>
</div>
<table class="foot">
  <tr>
    <td class="foot-date">Mon Jul 9 2018</td>
    <td class="foot-os">Version MetalPerformanceShaders-119.3</td>
  </tr>
</table>
</body>
</html>
