<!DOCTYPE html>
<html>
<!-- This is an automatically generated file.  Do not edit.
   -*- nroff -*-
 -->
<head>

<style>
@media (prefers-color-scheme: dark) {
  body {
    background: #000;
    color: #d0d0d0;
  }

  a, a:visited {
    color: #1899eb;
  }
}
</style>

  <meta charset="utf-8"/>
  <style>
    table.head, table.foot { width: 100%; }
    td.head-rtitle, td.foot-os { text-align: right; }
    td.head-vol { text-align: center; }
    div.Pp { margin: 1ex 0ex; }
    div.Nd, div.Bf, div.Op { display: inline; }
    span.Pa, span.Ad { font-style: italic; }
    span.Ms { font-weight: bold; }
    dl.Bl-diag > dt { font-weight: bold; }
    code.Nm, code.Fl, code.Cm, code.Ic, code.In, code.Fd, code.Fn,
    code.Cd { font-weight: bold; font-family: inherit; }
  </style>
  <title>MPSCNNConvolutionDescriptor(3)</title>
</head>
<body>
<table class="head">
  <tr>
    <td class="head-ltitle">MPSCNNConvolutionDescriptor(3)</td>
    <td class="head-vol">MetalPerformanceShaders.framework</td>
    <td class="head-rtitle">MPSCNNConvolutionDescriptor(3)</td>
  </tr>
</table>
<div class="manual-text">
<section class="Sh">
<h1 class="Sh" id="NAME"><a class="permalink" href="#NAME">NAME</a></h1>
MPSCNNConvolutionDescriptor
</section>
<section class="Sh">
<h1 class="Sh" id="SYNOPSIS"><a class="permalink" href="#SYNOPSIS">SYNOPSIS</a></h1>
<p class="Pp">#import &lt;MPSCNNConvolution.h&gt;</p>
<p class="Pp">Inherits NSObject, &lt;NSSecureCoding&gt;, and
  &lt;NSCopying&gt;.</p>
<p class="Pp">Inherited by <b>MPSCNNDepthWiseConvolutionDescriptor</b>, and
    <b>MPSCNNSubPixelConvolutionDescriptor</b>.</p>
<section class="Ss">
<h2 class="Ss" id="Instance_Methods"><a class="permalink" href="#Instance_Methods">Instance
  Methods</a></h2>
<br/>
(void) - <b>encodeWithCoder:</b>
<br/>
(nullable instancetype) - <b>initWithCoder:</b>
<br/>
(void) -
  <b>setBatchNormalizationParametersForInferenceWithMean:variance:gamma:beta:epsilon:</b>
<br/>
(void) - <b>setNeuronType:parameterA:parameterB:</b>
<br/>
(<b>MPSCNNNeuronType</b>) - <b>neuronType</b>
<br/>
(float) - <b>neuronParameterA</b>
<br/>
(float) - <b>neuronParameterB</b>
<br/>
(void) - <b>setNeuronToPReLUWithParametersA:</b>
<br/>
<br/>
</section>
<section class="Ss">
<h2 class="Ss" id="Class_Methods"><a class="permalink" href="#Class_Methods">Class
  Methods</a></h2>
<br/>
(nonnull instancetype) +
  <b>cnnConvolutionDescriptorWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:neuronFilter:</b>
<br/>
(nonnull instancetype) +
  <b>cnnConvolutionDescriptorWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:</b>
<br/>
<br/>
</section>
<section class="Ss">
<h2 class="Ss" id="Properties"><a class="permalink" href="#Properties">Properties</a></h2>
<br/>
NSUInteger <b>kernelWidth</b>
<br/>
NSUInteger <b>kernelHeight</b>
<br/>
NSUInteger <b>inputFeatureChannels</b>
<br/>
NSUInteger <b>outputFeatureChannels</b>
<br/>
NSUInteger <b>strideInPixelsX</b>
<br/>
NSUInteger <b>strideInPixelsY</b>
<br/>
NSUInteger <b>groups</b>
<br/>
NSUInteger <b>dilationRateX</b>
<br/>
NSUInteger <b>dilationRateY</b>
<br/>
<b>MPSNNNeuronDescriptor</b> *__nonnull <b>fusedNeuronDescriptor</b>
<br/>
const <b>MPSCNNNeuron</b> *__nullable <b>neuron</b>
<br/>
const <b>MPSCNNNeuron</b> *__nullable BOOL <b>supportsSecureCoding</b>
<br/>
<br/>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Detailed_Description"><a class="permalink" href="#Detailed_Description">Detailed
  Description</a></h1>
This depends on Metal.framework The <b>MPSCNNConvolutionDescriptor</b> specifies
  a convolution descriptor
</section>
<section class="Sh">
<h1 class="Sh" id="Method_Documentation"><a class="permalink" href="#Method_Documentation">Method
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss" id="+_(nonnull_instancetype)_cnnConvolutionDescriptorWithKernelWidth:_(NSUInteger)_kernelWidth(NSUInteger)_kernelHeight(NSUInteger)_inputFeatureChannels(NSUInteger)_outputFeatureChannels"><a class="permalink" href="#+_(nonnull_instancetype)_cnnConvolutionDescriptorWithKernelWidth:_(NSUInteger)_kernelWidth(NSUInteger)_kernelHeight(NSUInteger)_inputFeatureChannels(NSUInteger)_outputFeatureChannels">+
  (nonnull instancetype) cnnConvolutionDescriptorWithKernelWidth: (NSUInteger)
  kernelWidth(NSUInteger) kernelHeight(NSUInteger)
  inputFeatureChannels(NSUInteger) outputFeatureChannels</a></h2>
Creates a convolution descriptor.
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>kernelWidth</i> The width of the filter window. Must
  be &gt; 0. Large values will take a long time.
<br/>
<i>kernelHeight</i> The height of the filter window. Must be &gt; 0. Large
  values will take a long time.
<br/>
<i>inputFeatureChannels</i> The number of feature channels in the input image.
  Must be &gt;= 1.
<br/>
<i>outputFeatureChannels</i> The number of feature channels in the output image.
  Must be &gt;= 1.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> valid <b>MPSCNNConvolutionDescriptor</b> object
  or nil, if failure.</div>
</section>
<section class="Ss">
<h2 class="Ss" id="+_(nonnull_instancetype)_cnnConvolutionDescriptorWithKernelWidth:_(NSUInteger)_kernelWidth(NSUInteger)_kernelHeight(NSUInteger)_inputFeatureChannels(NSUInteger)_outputFeatureChannels(const__fBMPSCNNNeuron_fP_*__nullable)_neuronFilter"><a class="permalink" href="#+_(nonnull_instancetype)_cnnConvolutionDescriptorWithKernelWidth:_(NSUInteger)_kernelWidth(NSUInteger)_kernelHeight(NSUInteger)_inputFeatureChannels(NSUInteger)_outputFeatureChannels(const__fBMPSCNNNeuron_fP_*__nullable)_neuronFilter">+
  (nonnull instancetype) cnnConvolutionDescriptorWithKernelWidth: (NSUInteger)
  kernelWidth(NSUInteger) kernelHeight(NSUInteger)
  inputFeatureChannels(NSUInteger) outputFeatureChannels(const
  <b>MPSCNNNeuron</b> *__nullable) neuronFilter</a></h2>
This method is deprecated. Please use neuronType, neuronParameterA and
  neuronParameterB properites to fuse neuron with convolution.
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>kernelWidth</i> The width of the filter window. Must
  be &gt; 0. Large values will take a long time.
<br/>
<i>kernelHeight</i> The height of the filter window. Must be &gt; 0. Large
  values will take a long time.
<br/>
<i>inputFeatureChannels</i> The number of feature channels in the input image.
  Must be &gt;= 1.
<br/>
<i>outputFeatureChannels</i> The number of feature channels in the output image.
  Must be &gt;= 1.
<br/>
<i>neuronFilter</i> An optional neuron filter that can be applied to the output
  of convolution.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> valid <b>MPSCNNConvolutionDescriptor</b> object
  or nil, if failure.</div>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(void)_encodeWithCoder:_(NSCoder_*__nonnull)_aCoder"><a class="permalink" href="#_-_(void)_encodeWithCoder:_(NSCoder_*__nonnull)_aCoder">-
  (void) encodeWithCoder: (NSCoder *__nonnull) aCoder</a></h2>
&lt;NSSecureCoding&gt; support
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(nullable_instancetype)_initWithCoder:_(NSCoder_*__nonnull)_aDecoder"><a class="permalink" href="#_-_(nullable_instancetype)_initWithCoder:_(NSCoder_*__nonnull)_aDecoder">-
  (nullable instancetype) initWithCoder: (NSCoder *__nonnull) aDecoder</a></h2>
&lt;NSSecureCoding&gt; support
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(float)_neuronParameterA"><a class="permalink" href="#_-_(float)_neuronParameterA">-
  (float) neuronParameterA </a></h2>
Getter funtion for neuronType set using setNeuronType:parameterA:parameterB
  method
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(float)_neuronParameterB"><a class="permalink" href="#_-_(float)_neuronParameterB">-
  (float) neuronParameterB </a></h2>
Getter funtion for neuronType set using setNeuronType:parameterA:parameterB
  method
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(_fBMPSCNNNeuronType_fP)_neuronType"><a class="permalink" href="#_-_(_fBMPSCNNNeuronType_fP)_neuronType">-
  (<b>MPSCNNNeuronType</b>) neuronType </a></h2>
Getter funtion for neuronType set using setNeuronType:parameterA:parameterB
  method
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(void)_setBatchNormalizationParametersForInferenceWithMean:_(const_float_*__nullable)_mean(const_float_*__nullable)_variance(const_float_*__nullable)_gamma(const_float_*__nullable)_beta(const_float)_epsilon"><a class="permalink" href="#_-_(void)_setBatchNormalizationParametersForInferenceWithMean:_(const_float_*__nullable)_mean(const_float_*__nullable)_variance(const_float_*__nullable)_gamma(const_float_*__nullable)_beta(const_float)_epsilon">-
  (void) setBatchNormalizationParametersForInferenceWithMean: (const float
  *__nullable) mean(const float *__nullable) variance(const float *__nullable)
  gamma(const float *__nullable) beta(const float) epsilon</a></h2>
Adds batch normalization for inference, it copies all the float arrays provided,
  expecting outputFeatureChannels elements in each.
<p class="Pp">This method will be used to pass in batch normalization parameters
    to the convolution during the init call. For inference we modify weights and
    bias going in convolution or Fully Connected layer to combine and optimize
    the layers.</p>
<p class="Pp"></p>
<pre>
        w: weights for a corresponding output feature channel
        b: bias for a corresponding output feature channel
        W: batch normalized weights for a corresponding output feature channel
        B: batch normalized bias for a corresponding output feature channel
        I = gamma / sqrt(variance + epsilon), J = beta - ( I * mean )
        W = w * I
        B = b * I + J
        Every convolution has (OutputFeatureChannel * kernelWidth * kernelHeight * InputFeatureChannel) weights
        I, J are calculated, for every output feature channel separately to get the corresponding weights and bias
        Thus, I, J are calculated and then used for every (kernelWidth * kernelHeight * InputFeatureChannel)
        weights, and this is done OutputFeatureChannel number of times for each output channel.
        thus, internally, batch normalized weights are computed as:
        W[no][i][j][ni] = w[no][i][j][ni] * I[no]
        no: index into outputFeatureChannel
        i : index into kernel Height
        j : index into kernel Width
        ni: index into inputFeatureChannel
        One usually doesn't see a bias term and batch normalization together as batch normalization potentially cancels
        out the bias term after training, but in MPS if the user provides it, batch normalization will use the above 
        formula to incorporate it, if user does not have bias terms then put a float array of zeroes in the convolution
        init for bias terms of each output feature channel.
        this comes from:
        https://arxiv.org/pdf/1502.03167v3.pdf
        Note: in certain cases the batch normalization parameters will be cached by the MPSNNGraph
        or the MPSCNNConvolution. If the batch normalization parameters change after either is made,
        behavior is undefined.
</pre>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>mean</i> Pointer to an array of floats of mean for
  each output feature channel
<br/>
<i>variance</i> Pointer to an array of floats of variance for each output
  feature channel
<br/>
<i>gamma</i> Pointer to an array of floats of gamma for each output feature
  channel
<br/>
<i>beta</i> Pointer to an array of floats of beta for each output feature
  channel
<br/>
<i>epsilon</i> <b>A</b> small float value used to have numerical stability in
  the code</div>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(void)_setNeuronToPReLUWithParametersA:_(NSData_*__nonnull)_A"><a class="permalink" href="#_-_(void)_setNeuronToPReLUWithParametersA:_(NSData_*__nonnull)_A">-
  (void) setNeuronToPReLUWithParametersA: (NSData *__nonnull) A</a></h2>
Add per-channel neuron parameters <b>A</b> for PReLu neuron activation
  functions.
<p class="Pp">This method sets the neuron to PReLU, zeros parameters <b>A</b>
    and B and sets the per-channel neuron parameters <b>A</b> to an array
    containing a unique value of <b>A</b> for each output feature channel.</p>
<p class="Pp">If the neuron function is f(v,a,b), it will apply</p>
<p class="Pp"></p>
<pre>
   OutputImage(x,y,i) = f( ConvolutionResult(x,y,i), A[i], B[i] ) where i in [0,outputFeatureChannels-1]
</pre>
<p class="Pp">See https://arxiv.org/pdf/1502.01852.pdf for details.</p>
<p class="Pp">All other neuron types, where parameter <b>A</b> and parameter B
    are shared across channels must be set using
    -setNeuronOfType:parameterA:parameterB:</p>
<p class="Pp">If batch normalization parameters are set, batch normalization
    will occur before neuron application i.e. output of convolution is first
    batch normalized followed by neuron activation. This function automatically
    sets neuronType to MPSCNNNeuronTypePReLU.</p>
<p class="Pp">Note: in certain cases the neuron descriptor will be cached by the
    <b>MPSNNGraph</b> or the <b>MPSCNNConvolution</b>. If the neuron type
    changes after either is made, behavior is undefined.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i></i><b>A</b><i></i><b> An array containing per-channel
  float values for neuron parameter </b><b>A</b><b>. Number of entries must be
  equal to outputFeatureChannels.</b></div>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(void)_setNeuronType:_(_fBMPSCNNNeuronType_fP)_neuronType(float)_parameterA(float)_parameterB"><a class="permalink" href="#_-_(void)_setNeuronType:_(_fBMPSCNNNeuronType_fP)_neuronType(float)_parameterA(float)_parameterB">-
  (void) setNeuronType: (<b>MPSCNNNeuronType</b>) neuronType(float)
  parameterA(float) parameterB</a></h2>
Adds a neuron activation function to convolution descriptor.
<p class="Pp">This mathod can be used to add a neuron activation funtion of
    given type with associated scalar parameters <b>A</b> and B that are shared
    across all output channels. Neuron activation fucntion is applied to output
    of convolution. This is a per-pixel operation that is fused with convolution
    kernel itself for best performance. Note that this method can only be used
    to fuse neuron of kind for which parameters <b>A</b> and B are shared across
    all channels of convoution output. It is an error to call this method for
    neuron activation functions like MPSCNNNeuronTypePReLU, which require
    per-channel parameter values. For those kind of neuron activation functions,
    use appropriate setter functions.</p>
<p class="Pp">Note: in certain cases, the neuron descriptor will be cached by
    the <b>MPSNNGraph</b> or the <b>MPSCNNConvolution</b>. If the neuron type
    changes after either is made, behavior is undefined.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>neuronType</i> type of neuron activation function. For
  full list see <b>MPSCNNNeuronType.h</b>
<br/>
<i>parameterA</i> parameterA of neuron activation that is shared across all
  channels of convolution output.
<br/>
<i>parameterB</i> parameterB of neuron activation that is shared across all
  channels of convolution output.</div>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Property_Documentation"><a class="permalink" href="#Property_Documentation">Property
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss" id="_-_dilationRateX_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_dilationRateX_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  dilationRateX [read]<i>, [write]</i>, [nonatomic]<i>, [assign]</i></a></h2>
dilationRateX property can be used to implement dilated convolution as described
  in https://arxiv.org/pdf/1511.07122v3.pdf to aggregate global information in
  dense prediction problems. Default value is 1. When set to value &gt; 1,
  original kernel width, kW is dilated to
<p class="Pp"></p>
<pre>
  kW_Dilated = (kW-1)*dilationRateX + 1
</pre>
<p class="Pp">by inserting d-1 zeros between consecutive entries in each row of
    the original kernel. The kernel is centered based on kW_Dilated.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_dilationRateY_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_dilationRateY_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  dilationRateY [read]<i>, [write]</i>, [nonatomic]<i>, [assign]</i></a></h2>
dilationRateY property can be used to implement dilated convolution as described
  in https://arxiv.org/pdf/1511.07122v3.pdf to aggregate global information in
  dense prediction problems. Default value is 1. When set to value &gt; 1,
  original kernel height, kH is dilated to
<p class="Pp"></p>
<pre>
  kH_Dilated = (kH-1)*dilationRateY + 1
</pre>
<p class="Pp">by inserting d-1 rows of zeros between consecutive row of the
    original kernel. The kernel is centered based on kH_Dilated.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_fusedNeuronDescriptor_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__retain__fP"><a class="permalink" href="#_-_fusedNeuronDescriptor_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__retain__fP">-
  fusedNeuronDescriptor [read]<i>, [write]</i>, [nonatomic]<i>,
  [retain]</i></a></h2>
This mathod can be used to add a neuron activation funtion of given type with
  associated scalar parameters <b>A</b> and B that are shared across all output
  channels. Neuron activation fucntion is applied to output of convolution. This
  is a per-pixel operation that is fused with convolution kernel itself for best
  performance. Note that this method can only be used to fuse neuron of kind for
  which parameters <b>A</b> and B are shared across all channels of convoution
  output. It is an error to call this method for neuron activation functions
  like MPSCNNNeuronTypePReLU, which require per-channel parameter values. For
  those kind of neuron activation functions, use appropriate setter functions.
  Default is descriptor with neuronType MPSCNNNeuronTypeNone.
<p class="Pp">Note: in certain cases the neuron descriptor will be cached by the
    <b>MPSNNGraph</b> or the <b>MPSCNNConvolution</b>. If the neuron type
    changes after either is made, behavior is undefined.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_groups_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_groups_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  groups [read]<b>, [write]</b>, [nonatomic]<b>, [assign]</b></a></h2>
Number of groups input and output channels are divided into. The default value
  is 1. Groups lets you reduce the parameterization. If groups is set to n,
  input is divided into n groups with inputFeatureChannels/n channels in each
  group. Similarly output is divided into n groups with outputFeatureChannels/n
  channels in each group. ith group in input is only connected to ith group in
  output so number of weights (parameters) needed is reduced by factor of n.
  Both inputFeatureChannels and outputFeatureChannels must be divisible by n and
  number of channels in each group must be multiple of 4.
</section>
<section class="Ss">
<h2 class="Ss" id="_-_inputFeatureChannels_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_inputFeatureChannels_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  inputFeatureChannels [read]<b>, [write]</b>, [nonatomic]<b>,
  [assign]</b></a></h2>
The number of feature channels per pixel in the input image.
</section>
<section class="Ss">
<h2 class="Ss" id="_-_kernelHeight_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_kernelHeight_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  kernelHeight [read]<b>, [write]</b>, [nonatomic]<b>, [assign]</b></a></h2>
The height of the filter window. The default value is 3. Any positive non-zero
  value is valid, including even values. The position of the top edge of the
  filter window is given by offset.y - (kernelHeight&gt;&gt;1)
</section>
<section class="Ss">
<h2 class="Ss" id="_-_kernelWidth_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_kernelWidth_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  kernelWidth [read]<b>, [write]</b>, [nonatomic]<b>, [assign]</b></a></h2>
The width of the filter window. The default value is 3. Any positive non-zero
  value is valid, including even values. The position of the left edge of the
  filter window is given by offset.x - (kernelWidth&gt;&gt;1)
</section>
<section class="Ss">
<h2 class="Ss" id="_-_neuron_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__retain__fP"><a class="permalink" href="#_-_neuron_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__retain__fP">-
  neuron [read]<b>, [write]</b>, [nonatomic]<b>, [retain]</b></a></h2>
<b>MPSCNNNeuron</b> filter to be applied as part of convolution. This is applied
  after BatchNormalization in the end. Default is nil. This is deprecated. You
  dont need to create <b>MPSCNNNeuron</b> object to fuse with convolution. Use
  neuron properties in this descriptor.
</section>
<section class="Ss">
<h2 class="Ss" id="_-_outputFeatureChannels_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_outputFeatureChannels_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  outputFeatureChannels [read]<b>, [write]</b>, [nonatomic]<b>,
  [assign]</b></a></h2>
The number of feature channels per pixel in the output image.
</section>
<section class="Ss">
<h2 class="Ss" id="_-_strideInPixelsX_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_strideInPixelsX_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  strideInPixelsX [read]<b>, [write]</b>, [nonatomic]<b>, [assign]</b></a></h2>
The output stride (downsampling factor) in the x dimension. The default value is
  1.
</section>
<section class="Ss">
<h2 class="Ss" id="_-_strideInPixelsY_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_strideInPixelsY_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  strideInPixelsY [read]<b>, [write]</b>, [nonatomic]<b>, [assign]</b></a></h2>
The output stride (downsampling factor) in the y dimension. The default value is
  1.
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(const__fBMPSCNNNeuron_fP*___nullable_BOOL)_supportsSecureCoding_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_(const__fBMPSCNNNeuron_fP*___nullable_BOOL)_supportsSecureCoding_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  (const <b>MPSCNNNeuron</b>* __nullable BOOL) supportsSecureCoding [read]<b>,
  [nonatomic]</b>, [assign]<b></b></a></h2>
&lt;NSSecureCoding&gt; support
<p class="Pp"></p>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Author"><a class="permalink" href="#Author">Author</a></h1>
Generated automatically by Doxygen for MetalPerformanceShaders.framework from
  the source code.
</section>
</div>
<table class="foot">
  <tr>
    <td class="foot-date">Mon Jul 9 2018</td>
    <td class="foot-os">Version MetalPerformanceShaders-119.3</td>
  </tr>
</table>
</body>
</html>
