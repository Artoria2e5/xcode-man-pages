<!DOCTYPE html>
<html>
<!-- This is an automatically generated file.  Do not edit.
   -*- nroff -*-
 -->
<head>

<style>
@media (prefers-color-scheme: dark) {
  body {
    background: #000;
    color: #d0d0d0;
  }

  a, a:visited {
    color: #1899eb;
  }
}
</style>

  <meta charset="utf-8"/>
  <style>
    table.head, table.foot { width: 100%; }
    td.head-rtitle, td.foot-os { text-align: right; }
    td.head-vol { text-align: center; }
    div.Pp { margin: 1ex 0ex; }
    div.Nd, div.Bf, div.Op { display: inline; }
    span.Pa, span.Ad { font-style: italic; }
    span.Ms { font-weight: bold; }
    dl.Bl-diag > dt { font-weight: bold; }
    code.Nm, code.Fl, code.Cm, code.Ic, code.In, code.Fd, code.Fn,
    code.Cd { font-weight: bold; font-family: inherit; }
  </style>
  <title>MPSNNOptimizerStochasticGradientDescent(3)</title>
</head>
<body>
<table class="head">
  <tr>
    <td class="head-ltitle">MPSNNOptimizerStochasticGradientDescent(3)</td>
    <td class="head-vol">MetalPerformanceShaders.framework</td>
    <td class="head-rtitle">MPSNNOptimizerStochasticGradientDescent(3)</td>
  </tr>
</table>
<div class="manual-text">
<section class="Sh">
<h1 class="Sh" id="NAME"><a class="permalink" href="#NAME">NAME</a></h1>
MPSNNOptimizerStochasticGradientDescent
</section>
<section class="Sh">
<h1 class="Sh" id="SYNOPSIS"><a class="permalink" href="#SYNOPSIS">SYNOPSIS</a></h1>
<p class="Pp">#import &lt;MPSNNOptimizers.h&gt;</p>
<p class="Pp">Inherits <b>MPSNNOptimizer</b>.</p>
<section class="Ss">
<h2 class="Ss" id="Instance_Methods"><a class="permalink" href="#Instance_Methods">Instance
  Methods</a></h2>
<br/>
(nonnull instancetype) - <b>initWithDevice:</b>
<br/>
(nonnull instancetype) - <b>initWithDevice:learningRate:</b>
<br/>
(nonnull instancetype) -
  <b>initWithDevice:momentumScale:useNestrovMomentum:optimizerDescriptor:</b>
<br/>
(void) -
  <b>encodeToCommandBuffer:inputGradientVector:inputValuesVector:inputMomentumVector:resultValuesVector:</b>
<br/>
(void) -
  <b>encodeToCommandBuffer:convolutionGradientState:convolutionSourceState:inputMomentumVectors:resultState:</b>
<br/>
(void) -
  <b>encodeToCommandBuffer:batchNormalizationState:inputMomentumVectors:resultState:</b>
<br/>
(void) -
  <b>encodeToCommandBuffer:batchNormalizationGradientState:batchNormalizationSourceState:inputMomentumVectors:resultState:</b>
<br/>
<br/>
</section>
<section class="Ss">
<h2 class="Ss" id="Properties"><a class="permalink" href="#Properties">Properties</a></h2>
<br/>
float <b>momentumScale</b>
<br/>
BOOL <b>useNestrovMomentum</b>
<br/>
<br/>
</section>
<section class="Ss">
<h2 class="Ss" id="Additional_Inherited_Members"><a class="permalink" href="#Additional_Inherited_Members">Additional
  Inherited Members</a></h2>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Detailed_Description"><a class="permalink" href="#Detailed_Description">Detailed
  Description</a></h1>
The <b>MPSNNOptimizerStochasticGradientDescent</b> performs a gradient descent
  with an optional momentum Update RMSProp is also known as root mean square
  propagation.
<p class="Pp">useNestrov == NO: m[t] = momentumScale * m[t-1] + learningRate * g
    variable = variable - m[t]</p>
<p class="Pp">useNestrov == YES: m[t] = momentumScale * m[t-1] + g variable =
    variable - (learningRate * (g + m[t] * momentumScale))</p>
<p class="Pp"></p>
<pre>
        where,
          g    is gradient of error wrt variable
          m[t] is momentum of gradients it is a state we keep updating every update iteration.fi
</pre>
<pre>
 
</pre>
</section>
<section class="Sh">
<h1 class="Sh" id="Method_Documentation"><a class="permalink" href="#Method_Documentation">Method
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss" id="_-_(void)_encodeToCommandBuffer:_(__nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSCNNBatchNormalizationState_fP_*__nonnull)_batchNormalizationGradientState(_fBMPSCNNBatchNormalizationState_fP_*__nonnull)_batchNormalizationSourceState(nullable_NSArray___fBMPSVector_fP_*___*)_inputMomentumVectors(nonnull__fBMPSCNNNormalizationGammaAndBetaState_fP_*)_resultState"><a class="permalink" href="#_-_(void)_encodeToCommandBuffer:_(__nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSCNNBatchNormalizationState_fP_*__nonnull)_batchNormalizationGradientState(_fBMPSCNNBatchNormalizationState_fP_*__nonnull)_batchNormalizationSourceState(nullable_NSArray___fBMPSVector_fP_*___*)_inputMomentumVectors(nonnull__fBMPSCNNNormalizationGammaAndBetaState_fP_*)_resultState">-
  (void) encodeToCommandBuffer: (__nonnull id&lt; MTLCommandBuffer &gt;)
  commandBuffer(<b>MPSCNNBatchNormalizationState</b> *__nonnull)
  batchNormalizationGradientState(<b>MPSCNNBatchNormalizationState</b>
  *__nonnull) batchNormalizationSourceState(nullable NSArray&lt;
  <b>MPSVector</b> * &gt; *) inputMomentumVectors(nonnull
  <b>MPSCNNNormalizationGammaAndBetaState</b> *) resultState</a></h2>
Encode an <b>MPSNNOptimizerStochasticGradientDescent</b> object to a command
  buffer to perform out of place update
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> <b>A</b> valid MTLCommandBuffer to
  receive the encoded kernel.
<br/>
<i>batchNormalizationGradientState</i> <b>A</b> valid
  <b>MPSCNNBatchNormalizationState</b> object which specifies the input state
  with gradients for this update.
<br/>
<i>batchNormalizationSourceState</i> <b>A</b> valid
  <b>MPSCNNBatchNormalizationState</b> object which specifies the input state
  with original gamma/beta for this update.
<br/>
<i>inputMomentumVectors</i> An array <b>MPSVector</b> object which specifies the
  gradient momentum vectors which will be updated and overwritten. The index 0
  corresponds to gamma, index 1 corresponds to beta, array can be of size 1 in
  which case beta won't be updated
<br/>
<i>resultState</i> <b>A</b> valid <b>MPSCNNNormalizationGammaAndBetaState</b>
  object which specifies the resultValues state which will be updated and
  overwritten.</div>
<p class="Pp">The following operations would be applied</p>
<p class="Pp"></p>
<pre>
        useNestrov == NO:
            m[t]     = momentumScale * m[t-1] + learningRate * g
            variable = variable - m[t]
        useNestrov == YES:
            m[t]     = momentumScale * m[t-1] + g
            variable = variable - (learningRate * (g + m[t] * momentumScale))
        inputMomentumVector == nil
            variable = variable - (learningRate * g)
        where,
          g    is gradient of error wrt variable
          m[t] is momentum of gradients it is a state we keep updating every update iteration.fi
</pre>
<pre>
 
</pre>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(void)_encodeToCommandBuffer:_(__nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSCNNBatchNormalizationState_fP_*__nonnull)_batchNormalizationState(nullable_NSArray___fBMPSVector_fP_*___*)_inputMomentumVectors(nonnull__fBMPSCNNNormalizationGammaAndBetaState_fP_*)_resultState"><a class="permalink" href="#_-_(void)_encodeToCommandBuffer:_(__nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSCNNBatchNormalizationState_fP_*__nonnull)_batchNormalizationState(nullable_NSArray___fBMPSVector_fP_*___*)_inputMomentumVectors(nonnull__fBMPSCNNNormalizationGammaAndBetaState_fP_*)_resultState">-
  (void) encodeToCommandBuffer: (__nonnull id&lt; MTLCommandBuffer &gt;)
  commandBuffer(<b>MPSCNNBatchNormalizationState</b> *__nonnull)
  batchNormalizationState(nullable NSArray&lt; <b>MPSVector</b> * &gt; *)
  inputMomentumVectors(nonnull <b>MPSCNNNormalizationGammaAndBetaState</b> *)
  resultState</a></h2>
Encode an <b>MPSNNOptimizerStochasticGradientDescent</b> object to a command
  buffer to perform out of place update
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> <b>A</b> valid MTLCommandBuffer to
  receive the encoded kernel.
<br/>
<i>batchNormalizationState</i> <b>A</b> valid
  <b>MPSCNNBatchNormalizationState</b> object which specifies the input state
  with gradients and original gamma/beta for this update.
<br/>
<i>inputMomentumVectors</i> An array <b>MPSVector</b> object which specifies the
  gradient momentum vectors which will be updated and overwritten. The index 0
  corresponds to gamma, index 1 corresponds to beta, array can be of size 1 in
  which case beta won't be updated
<br/>
<i>resultState</i> <b>A</b> valid <b>MPSCNNNormalizationGammaAndBetaState</b>
  object which specifies the resultValues state which will be updated and
  overwritten.</div>
<p class="Pp">The following operations would be applied</p>
<p class="Pp"></p>
<pre>
        useNestrov == NO:
            m[t]     = momentumScale * m[t-1] + learningRate * g
            variable = variable - m[t]
        useNestrov == YES:
            m[t]     = momentumScale * m[t-1] + g
            variable = variable - (learningRate * (g + m[t] * momentumScale))
        inputMomentumVector == nil
            variable = variable - (learningRate * g)
        where,
          g    is gradient of error wrt variable
          m[t] is momentum of gradients it is a state we keep updating every update iteration.fi
</pre>
<pre>
 
</pre>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(void)_encodeToCommandBuffer:_(__nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSCNNConvolutionGradientState_fP_*__nonnull)_convolutionGradientState(_fBMPSCNNConvolutionWeightsAndBiasesState_fP_*__nonnull)_convolutionSourceState(nullable_NSArray___fBMPSVector_fP_*___*)_inputMomentumVectors(nonnull__fBMPSCNNConvolutionWeightsAndBiasesState_fP_*)_resultState"><a class="permalink" href="#_-_(void)_encodeToCommandBuffer:_(__nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSCNNConvolutionGradientState_fP_*__nonnull)_convolutionGradientState(_fBMPSCNNConvolutionWeightsAndBiasesState_fP_*__nonnull)_convolutionSourceState(nullable_NSArray___fBMPSVector_fP_*___*)_inputMomentumVectors(nonnull__fBMPSCNNConvolutionWeightsAndBiasesState_fP_*)_resultState">-
  (void) encodeToCommandBuffer: (__nonnull id&lt; MTLCommandBuffer &gt;)
  commandBuffer(<b>MPSCNNConvolutionGradientState</b> *__nonnull)
  convolutionGradientState(<b>MPSCNNConvolutionWeightsAndBiasesState</b>
  *__nonnull) convolutionSourceState(nullable NSArray&lt; <b>MPSVector</b> *
  &gt; *) inputMomentumVectors(nonnull
  <b>MPSCNNConvolutionWeightsAndBiasesState</b> *) resultState</a></h2>
Encode an <b>MPSNNOptimizerStochasticGradientDescent</b> object to a command
  buffer to perform out of place update
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> <b>A</b> valid MTLCommandBuffer to
  receive the encoded kernel.
<br/>
<i>convolutionGradientState</i> <b>A</b> valid
  <b>MPSCNNConvolutionGradientState</b> object which specifies the input state
  with gradients for this update.
<br/>
<i>convolutionSourceState</i> <b>A</b> valid
  <b>MPSCNNConvolutionWeightsAndBiasesState</b> object which specifies the input
  state with values to be updated.
<br/>
<i>inputMomentumVectors</i> An array <b>MPSVector</b> object which specifies the
  gradient momentum vectors which will be updated and overwritten. The index 0
  corresponds to weights, index 1 corresponds to biases, array can be of size 1
  in which case biases won't be updated
<br/>
<i>resultState</i> <b>A</b> valid <b>MPSCNNConvolutionWeightsAndBiasesState</b>
  object which specifies the resultValues state which will be updated and
  overwritten.</div>
<p class="Pp">The following operations would be applied</p>
<p class="Pp"></p>
<pre>
        useNestrov == NO:
            m[t]     = momentumScale * m[t-1] + learningRate * g
            variable = variable - m[t]
        useNestrov == YES:
            m[t]     = momentumScale * m[t-1] + g
            variable = variable - (learningRate * (g + m[t] * momentumScale))
        inputMomentumVector == nil
            variable = variable - (learningRate * g)
        where,
          g    is gradient of error wrt variable
          m[t] is momentum of gradients it is a state we keep updating every update iteration.fi
</pre>
<pre>
 
</pre>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(void)_encodeToCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(nonnull__fBMPSVector_fP_*)_inputGradientVector(nonnull__fBMPSVector_fP_*)_inputValuesVector(nullable__fBMPSVector_fP_*)_inputMomentumVector(nonnull__fBMPSVector_fP_*)_resultValuesVector"><a class="permalink" href="#_-_(void)_encodeToCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(nonnull__fBMPSVector_fP_*)_inputGradientVector(nonnull__fBMPSVector_fP_*)_inputValuesVector(nullable__fBMPSVector_fP_*)_inputMomentumVector(nonnull__fBMPSVector_fP_*)_resultValuesVector">-
  (void) encodeToCommandBuffer: (nonnull id&lt; MTLCommandBuffer &gt;)
  commandBuffer(nonnull <b>MPSVector</b> *) inputGradientVector(nonnull
  <b>MPSVector</b> *) inputValuesVector(nullable <b>MPSVector</b> *)
  inputMomentumVector(nonnull <b>MPSVector</b> *) resultValuesVector</a></h2>
Encode an <b>MPSNNOptimizerStochasticGradientDescent</b> object to a command
  buffer to perform out of place update
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> <b>A</b> valid MTLCommandBuffer to
  receive the encoded kernel.
<br/>
<i>inputGradientVector</i> <b>A</b> valid <b>MPSVector</b> object which
  specifies the input vector of gradients for this update.
<br/>
<i>inputValuesVector</i> <b>A</b> valid <b>MPSVector</b> object which specifies
  the input vector of values to be updated.
<br/>
<i>inputMomentumVector</i> <b>A</b> valid <b>MPSVector</b> object which
  specifies the gradient momentum vector which will be updated and overwritten.
<br/>
<i>resultValuesVector</i> <b>A</b> valid <b>MPSVector</b> object which specifies
  the resultValues vector which will be updated and overwritten.</div>
<p class="Pp">The following operations would be applied</p>
<p class="Pp"></p>
<pre>
        useNestrov == NO:
            m[t]     = momentumScale * m[t-1] + learningRate * g
            variable = variable - m[t]
        useNestrov == YES:
            m[t]     = momentumScale * m[t-1] + g
            variable = variable - (learningRate * (g + m[t] * momentumScale))
        inputMomentumVector == nil
            variable = variable - (learningRate * g)
        where,
          g    is gradient of error wrt variable
          m[t] is momentum of gradients it is a state we keep updating every update iteration.fi
</pre>
<pre>
 
</pre>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(nonnull_instancetype)_initWithDevice:_(nonnull_id__MTLDevice__)_device"><a class="permalink" href="#_-_(nonnull_instancetype)_initWithDevice:_(nonnull_id__MTLDevice__)_device">-
  (nonnull instancetype) initWithDevice: (nonnull id&lt; MTLDevice &gt;)
  device</a></h2>
Standard init with default properties per filter type
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>device</i> The device that the filter will be used on.
  May not be NULL.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent">a pointer to the newly initialized object. This will
  fail, returning nil if the device is not supported. Devices must be
  MTLFeatureSet_iOS_GPUFamily2_v1 or later.</div>
<p class="Pp">Reimplemented from <b>MPSNNOptimizer</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(nonnull_instancetype)__fBinitWithDevice:_fP_(nonnull_id__MTLDevice__)_device(float)_learningRate"><a class="permalink" href="#_-_(nonnull_instancetype)__fBinitWithDevice:_fP_(nonnull_id__MTLDevice__)_device(float)_learningRate">-
  (nonnull instancetype) <b>initWithDevice:</b> (nonnull id&lt; MTLDevice &gt;)
  device(float) learningRate</a></h2>
Convenience initialization for the momentum update
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>device</i> The device on which the kernel will
  execute.
<br/>
<i>learningRate</i> The learningRate which will be applied</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> valid
  <b>MPSNNOptimizerStochasticGradientDescent</b> object or nil, if
  failure.</div>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(nonnull_instancetype)__fBinitWithDevice:_fP_(nonnull_id__MTLDevice__)_device(float)_momentumScale(BOOL)_useNestrovMomentum(nonnull__fBMPSNNOptimizerDescriptor_fP_*)_optimizerDescriptor"><a class="permalink" href="#_-_(nonnull_instancetype)__fBinitWithDevice:_fP_(nonnull_id__MTLDevice__)_device(float)_momentumScale(BOOL)_useNestrovMomentum(nonnull__fBMPSNNOptimizerDescriptor_fP_*)_optimizerDescriptor">-
  (nonnull instancetype) <b>initWithDevice:</b> (nonnull id&lt; MTLDevice &gt;)
  device(float) momentumScale(BOOL) useNestrovMomentum(nonnull
  <b>MPSNNOptimizerDescriptor</b> *) optimizerDescriptor</a></h2>
Full initialization for the momentum update
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>device</i> The device on which the kernel will
  execute.
<br/>
<i>momentumScale</i> The momentumScale to update momentum for values array
<br/>
<i>useNestrovMomentum</i> Use the Nestrov style momentum update
<br/>
<i>optimizerDescriptor</i> The optimizerDescriptor which will have a bunch of
  properties to be applied</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> valid MPSNNOptimizerMomentum object or nil, if
  failure.</div>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Property_Documentation"><a class="permalink" href="#Property_Documentation">Property
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss" id="_-_momentumScale_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_momentumScale_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  momentumScale [read]<b>, [nonatomic]</b>, [assign]<b></b></a></h2>
The momentumScale at which we update momentum for values array Default value is
  0.0
</section>
<section class="Ss">
<h2 class="Ss" id="_-_useNestrovMomentum_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_useNestrovMomentum_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  useNestrovMomentum [read]<b>, [nonatomic]</b>, [assign]<b></b></a></h2>
Nestrov momentum is considered an improvement on the usual momentum update
  Default value is NO
<p class="Pp"></p>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Author"><a class="permalink" href="#Author">Author</a></h1>
Generated automatically by Doxygen for MetalPerformanceShaders.framework from
  the source code.
</section>
</div>
<table class="foot">
  <tr>
    <td class="foot-date">Mon Jul 9 2018</td>
    <td class="foot-os">Version MetalPerformanceShaders-119.3</td>
  </tr>
</table>
</body>
</html>
